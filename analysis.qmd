---
title: "Analyzing the Forest"
subtitle: "Prelim Analysis"
author: "Matt McGehee (Advisor: Dr. Seals)"
date: last-modified
date-format: long
format:
  html:
    code-fold: true
    embed-resources: true
    self-contained-math: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction

The objective of this analysis is to apply the Random Forest algorithm to better understand patterns in sales data. The dataset contains sales information, including details such as `SalesOrderID`, `CustomerPO`, `TotalPrice`, `UnitPrice`, and `qtyOrdered`. The primary goals of the analysis include identifying important variables, detecting outliers, and predicting purchasing behavior.

Data cleaning was performed to remove outliers and filter out irrelevant products, such as shipping line items. Additionally, proximity analyses were conducted using the Random Forest proximity scores to further understand customer relationships and outlier detection.


## Load necessary libraries
```{r}
library(randomForest)
library(caret)
library(dplyr)
library(cluster)
library(knitr)
library(kableExtra)
```

## Data Extraction
Read in the data from the corresponding 'csv' file that contains the sales data.
```{r}
sales_data <- read.csv("data_as_csv.csv")
```

## Data Cleaning and Preprocessing
The raw dataset initially contained some irrelevant products, including shipping line items and "credits back" to customers, which were not relevant to our analysis. To ensure accurate analysis, the following filtering steps were applied:

- Excluded products related to shipping and fees, such as "OUTBOUND SHIPPING", "Shipping Charge".
- Filtered out negative `UnitPrice`, `TotalPrice`, and `qtyOrdered` values to focus on meaningful transactions.
- Grouped the dataset by `CustomerPO` to aggregate sales at the purchase order level and obtain summary statistics, such as total quantity ordered and total price per order.

This filtering step was critical in ensuring the dataset was clean and focused only on relevant, positive sales transactions.
```{r}
exclude_products <- c("OUTBOUND SHIPPING", "Outbound Shipping", "Shipping Charge", "SHIPPING CHARGE")

filtered_data <- sales_data %>%
  filter(UnitPrice > 0, TotalPrice > 0, qtyOrdered > 0, !Product %in% exclude_products)
```

### Variable Selection

In this analysis, variables like `TotalPrice`, `qtyOrdered`, and `UnitPrice` were prioritized because they provide direct insights into customer behavior, such as spending patterns and order size. 

`Product` and `Substrate` were omitted from the clustering and proximity analysis for the following reasons:
- **High Cardinality**: Both fields contain many unique values, which could introduce noise and reduce the effectiveness of clustering.
- **Relevance to Customer Segmentation**: The primary goal was to segment customers based on purchasing behavior. Variables like `TotalPrice` and `qtyOrdered` reflect customer activity more effectively than product-level details.
- **Avoiding Overfitting**: Including product-specific fields could lead to overfitting, where the model captures unnecessary product-level variations rather than broader purchasing patterns.

By focusing on generalizable metrics, the analysis was able to identify distinct customer segments based on behavior rather than specific products.

## Methodology

The Random Forest algorithm was employed in this analysis to predict customer behavior and assess feature importance. The steps included:

1. **Random Forest Classification**: Random Forest was used to predict purchasing behavior based on features such as `TotalPrice`, `qtyOrdered`, and `UnitPrice`. The modelâ€™s proximity scores were used to further analyze customer similarities and outliers.
   
2. **Proximity Analysis**: The proximity matrix generated by the Random Forest model was used to assess how closely customers were grouped based on their purchasing behavior. This enabled the identification of potential outliers and the detection of similar customer groups.

3. **Feature Importance**: The Random Forest model also provided insights into which variables were most important in predicting customer behavior, allowing for a better understanding of which factors drive sales.
   
4. **Outlier Detection**: Outliers were identified based on proximity measures from the Random Forest model. These outliers represent customers whose purchasing behavior deviated significantly from the rest of the dataset.

## Analysis
```{r}
cluster_data <- filtered_data %>%
  group_by(CustomerPO) %>%  # You can group by other variables like SalesOrderID if preferred
  summarise(
    TotalPrice = sum(TotalPrice),
    qtyOrdered = sum(qtyOrdered),
    UnitPrice = mean(UnitPrice)
  )

# Step 2: Summary statistics to detect outliers
summary(cluster_data)

# Step 4: Define threshold to filter out extreme outliers
quantile_threshold <- 0.99  # Remove top 1%
price_threshold <- quantile(cluster_data$TotalPrice, quantile_threshold)
qty_threshold <- quantile(cluster_data$qtyOrdered, quantile_threshold)

# Step 5: Filter out extreme outliers
cluster_data_filtered <- cluster_data %>%
  filter(TotalPrice <= price_threshold, qtyOrdered <= qty_threshold)

boxplot(cluster_data_filtered$TotalPrice, main = "Boxplot of TotalPrice", horizontal = TRUE)
boxplot(cluster_data_filtered$qtyOrdered, main = "Boxplot of qtyOrdered", horizontal = TRUE)

# Step 6: Fit Random Forest model (predicting TotalPrice based on qtyOrdered and UnitPrice)


```

### Figure 1: Feature Importance in Random Forest Model
This plot shows the relative importance of `qtyOrdered` and `UnitPrice` in predicting total order value (`TotalPrice`). Features with a higher increase in node purity (on the X-axis) contribute more to reducing the impurity in the model, indicating higher importance. Here, `qtyOrdered` is the most influential predictor of `TotalPrice`.
```{r}
set.seed(123)
# Create Random Forest model to determine feature importance
rf_model <- randomForest(TotalPrice ~ qtyOrdered + UnitPrice, data = cluster_data_filtered, ntree = 500, proximity = TRUE)
importance(rf_model)
varImpPlot(rf_model, main="Feature Importance in Random Forest Model", cex=0.8)
title(xlab="Increase in Node Purity", ylab="Features")
```

### Figure 2: Proximity Distribution from Random Forest
This plot visualizes the distribution of proximity scores across all customers. Lower proximity scores indicate that customers have similar purchasing behaviors, while higher scores suggest customers with more unique purchasing patterns.

```{r}
proximity_matrix <- rf_model$proximity

proximity_data <- as.data.frame(proximity_matrix)
proximity_data$CustomerPO <- rownames(proximity_matrix)

# Calculate the average proximity (distance) for each point
proximity_data$Proximity <- apply(proximity_matrix, 1, function(x) mean(x))

# Proximity Distribution Plot
ggplot(proximity_data, aes(x = Proximity)) +
  geom_density(alpha = 0.7, color="blue") +
  labs(title="Proximity Distribution from Random Forest",
       x="Proximity Score", y="Density") +
  theme_minimal()

outlier_threshold <- quantile(proximity_data$Proximity, 0.95)  # Top 5% as outliers
proximity_data$Segment <- ifelse(proximity_data$Proximity > outlier_threshold, "Outliers", "Main Group")
```

### Figure 3: Outlier Detection Based on Random Forest Proximity
This plot shows how customers are segmented into the "Main Group" and "Outliers" based on their proximity scores. Customers with lower proximity scores are grouped into the "Main Group," while customers with proximity scores in the top 5% are flagged as "Outliers," indicating unique purchasing behavior.

```{r}
# Outlier Detection Based on Proximity
ggplot(proximity_data, aes(x = Proximity, fill = Segment)) +
  geom_density(alpha = 0.7) +
  labs(title="Outlier Detection Based on Random Forest Proximity",
       x="Proximity Score", y="Density") +
  scale_fill_manual(values=c("Main Group"="red", "Outliers"="cyan")) +
  theme_minimal()
```

### Figure 4: Performance Metrics of the Random Forest Model
This bar chart shows the key performance metrics of the Random Forest model:
- **RMSE (Root Mean Square Error)** indicates the standard deviation of the residuals (prediction errors). Lower RMSE values represent a better fit of the model.
- **R-squared (Coefficient of Determination)** measures the proportion of variance in `TotalPrice` that is predictable from `qtyOrdered` and `UnitPrice`. A higher value indicates better model performance.
- **MAE (Mean Absolute Error)** provides the average magnitude of the prediction errors, where lower values indicate better accuracy.

```{r}
# Split Data into Training and Testing Sets
set.seed(123)
trainIndex <- createDataPartition(cluster_data_filtered$TotalPrice, p = 0.8, list = FALSE)
train_data <- cluster_data_filtered[trainIndex, ]
test_data <- cluster_data_filtered[-trainIndex, ]

# Train the Random Forest model on the training data
rf_train <- randomForest(TotalPrice ~ qtyOrdered + UnitPrice, data = train_data, ntree = 500)

# Test the model and predict on the test data
test_predictions <- predict(rf_train, test_data)

# Evaluate the performance
performance <- postResample(test_predictions, test_data$TotalPrice)

performance_metrics <- data.frame(
  Metric = c("RMSE", "R-squared", "MAE"),
  Value = c(performance["RMSE"], performance["Rsquared"], performance["MAE"])
)

kable(performance_metrics, col.names = c("Metric", "Value"), caption = "Performance Metrics of Random Forest Model") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

## Results

The Random Forest algorithm was used to analyze customer purchasing behavior, focusing on predicting total order value (`TotalPrice`) using features such as `qtyOrdered` and `UnitPrice`. 

### Feature Importance
The Random Forest model's feature importance analysis revealed that `qtyOrdered` was the most influential predictor of total order value, followed by `UnitPrice`. This indicates that the quantity of items ordered has the largest impact on the total sales amount, as expected.

### Proximity Analysis
Using the proximity matrix generated by the Random Forest model, customers were grouped based on their similarity in purchasing behavior. The proximity scores helped identify customers whose purchasing habits were similar, allowing for segmentation. A small number of customers were identified as outliers based on their proximity scores, suggesting that these customers exhibited unusual purchasing patterns.

### Outlier Detection
The top 5% of customers, based on their proximity scores, were flagged as outliers. These customers typically placed orders that deviated significantly from the overall purchasing behavior, either by placing unusually large or small orders. Detecting these outliers ensured that the model's insights were not overly influenced by extreme behaviors, and the proximity analysis helped in identifying these atypical purchasing patterns.

## Conclusion

This analysis applied the Random Forest algorithm to segment customers based on their purchasing behavior and to assess feature importance. The proximity matrix generated by the Random Forest model helped identify distinct customer behaviors, as well as outliers who exhibited unusual purchasing patterns.

The feature importance analysis revealed that variables like `TotalPrice` and `qtyOrdered` were most influential in predicting customer behavior. The proximity analysis allowed for the identification of customers with similar behaviors and helped to flag outliers based on their unique purchasing patterns.

Overall, Random Forest proved to be an effective tool for understanding customer segmentation, purchasing behavior, and outlier detection. Future work could expand on this by incorporating additional variables such as customer demographics or product categories to further refine customer behavior insights.


